#!/bin/bash
# å¿«é€Ÿè®­ç»ƒè„šæœ¬ - åœ¨144Kæ•°æ®é›†ä¸Šè®­ç»ƒ5ä¸ªepochè·å–baseline

echo "ğŸš€ å¼€å§‹å¿«é€Ÿè®­ç»ƒ (5 epochs on 144K videos)"
echo "ç›®çš„: è·å–baseline checkpointç”¨äºåç»­å®Œæ•´è¯„ä¼°"
echo ""

cd lip_agent_and_prompt_decoding_agent

# é…ç½®æœ€å°æ—¥å¿—è¾“å‡º
export CUDA_VISIBLE_DEVICES=0
export PYTORCH_CUDA_ALLOC_CONF=max_split_size_mb:128

# æ£€æŸ¥GPU
python3 -c "import torch; print(f'GPUå¯ç”¨: {torch.cuda.is_available()}'); print(f'GPUæ•°é‡: {torch.cuda.device_count()}')"

# è®­ç»ƒ5ä¸ªepoch
python3 train_lip_agent.py \
    --config configs/config.yaml \
    data.dataset=mvlrs_v1 \
    data.root_dir=../data \
    data.modality=video \
    data.batch_size=16 \
    data.num_workers=4 \
    trainer.max_epochs=5 \
    trainer.log_every_n_steps=500 \
    trainer.check_val_every_n_epoch=1 \
    trainer.limit_train_batches=1000 \
    trainer.limit_val_batches=100 \
    exp_name=mvlrs_baseline_5epoch \
    gpus=1

echo ""
echo "âœ… è®­ç»ƒå®Œæˆï¼Checkpointä¿å­˜åœ¨ results/lightning_logs/"
