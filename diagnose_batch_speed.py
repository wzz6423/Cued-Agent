#!/usr/bin/env python3
"""è¯Šæ–­å•ä¸ªbatchçš„å¤„ç†é€Ÿåº¦"""
import time
import torch
import sys
sys.path.insert(0, '/home/ubuntu/wzz/Cued-Agent')

print("\n" + "="*80)
print("ğŸ” æ€§èƒ½è¯Šæ–­ï¼šæ•°æ®åŠ è½½é€Ÿåº¦æµ‹è¯•")
print("="*80)

try:
    from lip_agent_and_prompt_decoding_agent.datamodule.data_module_CCS import DataModule
    
    print("\n1ï¸âƒ£  åˆå§‹åŒ–æ•°æ®æ¨¡å—...")
    t0 = time.time()
    
    dm = DataModule(
        lrs_root='/home/ubuntu/wzz/Cued-Agent/data/mvlrs_v1',
        landmark_root='/home/ubuntu/wzz/Cued-Agent/data/LRS2_landmarks',
        num_workers=2,
        batch_size=4,
        shuffle=False
    )
    dm.setup("fit")
    print(f"   âœ… è€—æ—¶: {time.time()-t0:.2f}s\n")
    
    print("2ï¸âƒ£  åŠ è½½å‰3ä¸ªbatch...")
    train_loader = dm.train_dataloader()
    times = []
    
    for i, batch in enumerate(train_loader):
        if i >= 3: break
        t = time.time()
        
        # è½¬åˆ°GPU
        if torch.cuda.is_available():
            for k in batch:
                if isinstance(batch[k], torch.Tensor):
                    batch[k] = batch[k].cuda()
        
        elapsed = time.time() - t
        times.append(elapsed)
        print(f"   Batch {i+1}: {elapsed:.3f}s")
    
    avg = sum(times) / len(times)
    total_batches = len(train_loader)
    epoch_hours = (avg * total_batches) / 3600
    
    print(f"\nğŸ“Š å¹³å‡batchè€—æ—¶: {avg:.3f}s")
    print(f"ğŸ“ˆ æ€»batchæ•°: {total_batches}")
    print(f"â³ å•epochè€—æ—¶: {epoch_hours:.2f}å°æ—¶")
    print(f"â³ 20è½®è€—æ—¶: {epoch_hours * 20:.1f}å°æ—¶")
    print("\n" + "="*80)
    
except Exception as e:
    print(f"âŒ é”™è¯¯: {e}")
    import traceback
    traceback.print_exc()
